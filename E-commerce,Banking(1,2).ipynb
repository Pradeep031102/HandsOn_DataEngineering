{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr5lW3gK3NXN",
        "outputId": "ee403f44-2d8b-4af6-f006-45f7483303ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"E-commerce Transactions\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "com_data = [\n",
        "    (1, 101, \"Laptop\", \"Electronics\", 1000, 1, 10, \"2023-08-01\"),\n",
        "    (2, 102, \"Smartphone\", \"Electronics\", 700, 2, 5, \"2023-08-01\"),\n",
        "    (3, 103, \"Shirt\", \"Fashion\", 40, 3, 0, \"2023-08-02\"),\n",
        "    (4, 104, \"Blender\", \"Home Appliance\", 150, 1, 15, \"2023-08-03\"),\n",
        "    (5, 101, \"Headphones\", \"Electronics\", 100, 2, 10, \"2023-08-03\"),\n",
        "    (6, 105, \"Shoes\", \"Fashion\", 60, 1, 20, \"2023-08-04\"),\n",
        "    (7, 106, \"Refrigerator\", \"Home Appliance\", 800, 1, 25, \"2023-08-05\"),\n",
        "    (8, 107, \"Book\", \"Books\", 20, 4, 0, \"2023-08-05\"),\n",
        "    (9, 108, \"Toaster\", \"Home Appliance\", 30, 1, 5, \"2023-08-06\"),\n",
        "    (10, 102, \"Tablet\", \"Electronics\", 300, 2, 10, \"2023-08-06\")\n",
        "]\n",
        "com_columns = [\"transaction_id\", \"customer_id\", \"product\", \"category\", \"price\", \"quantity\", \"discount_percentage\", \"transaction_date\"]\n",
        "df = spark.createDataFrame(com_data, com_columns)\n"
      ],
      "metadata": {
        "id": "xiGOtEUx343c"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Calculate the Total Revenue per Category\n",
        "df_with_revenue = df.withColumn(\"total_revenue\", col(\"price\") * col(\"quantity\") * (1 - col(\"discount_percentage\") / 100))\n",
        "revenue_per_category = df_with_revenue.groupBy(\"category\").agg(sum(\"total_revenue\").alias(\"total_revenue\"))\n",
        "revenue_per_category.show()\n",
        "\n",
        "\n",
        "# 2. Filter Transactions with a Discount Greater Than 10%\n",
        "discount_gt_10 = df.filter(col(\"discount_percentage\") > 10)\n",
        "discount_gt_10.show()\n",
        "\n",
        "# 3. Find the Most Expensive Product Sold\n",
        "most_expensive_product_df = df.orderBy(col(\"price\").desc()).limit(1)\n",
        "most_expensive_product_df.show()\n",
        "\n",
        "# 4. Calculate the Average Quantity of Products Sold per Category\n",
        "avg_quantity_per_category = df.groupBy(\"category\").agg(avg(\"quantity\").alias(\"avg_quantity\"))\n",
        "avg_quantity_per_category.show()\n",
        "\n",
        "# 5. Identify Customers Who Purchased More Than One Product\n",
        "customers_multiple_products = df.groupBy(\"transaction_id\", \"customer_id\").agg(count(\"product\").alias(\"product_count\")).filter(col(\"product_count\") > 1)\n",
        "customers_multiple_products.show()\n",
        "\n",
        "# 6. Find the Top 3 Highest Revenue Transactions\n",
        "transaction_revenue = df_with_revenue.groupBy(\"transaction_id\").agg(sum(\"total_revenue\").alias(\"transaction_revenue\"))\n",
        "top_3_transactions = transaction_revenue.orderBy(col(\"transaction_revenue\").desc()).limit(3)\n",
        "top_3_transactions.show()\n",
        "\n",
        "# 7. Calculate the Total Number of Transactions per Day\n",
        "transactions_per_day = df.groupBy(\"transaction_date\").agg(count(\"transaction_id\").alias(\"total_transactions\"))\n",
        "transactions_per_day.show()\n",
        "\n",
        "# 8. Find the Customer Who Spent the Most Money\n",
        "customer_spending = df_with_revenue.groupBy(\"customer_id\").agg(sum(\"total_revenue\").alias(\"total_spent\"))\n",
        "top_spender_df = customer_spending.orderBy(col(\"total_spent\").desc()).limit(1)\n",
        "top_spender_df.show()\n",
        "\n",
        "# 9. Calculate the Average Discount Given per Product Category\n",
        "avg_discount_per_category = df.groupBy(\"category\").agg(avg(\"discount_percentage\").alias(\"avg_discount\"))\n",
        "avg_discount_per_category.show()\n",
        "\n",
        "# 10. Create a New Column for Final Price After Discount\n",
        "df_with_final_price = df.withColumn(\"final_price\", col(\"price\") * (1 - col(\"discount_percentage\") / 100))\n",
        "df_with_final_price.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXWZ5pFU4HIA",
        "outputId": "35a7b120-9b02-4591-b2dc-bfa4c9a4d889"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-------------+\n",
            "|      category|total_revenue|\n",
            "+--------------+-------------+\n",
            "|       Fashion|        168.0|\n",
            "|   Electronics|       2950.0|\n",
            "|Home Appliance|        756.0|\n",
            "|         Books|         80.0|\n",
            "+--------------+-------------+\n",
            "\n",
            "+--------------+-----------+------------+--------------+-----+--------+-------------------+----------------+\n",
            "|transaction_id|customer_id|     product|      category|price|quantity|discount_percentage|transaction_date|\n",
            "+--------------+-----------+------------+--------------+-----+--------+-------------------+----------------+\n",
            "|             4|        104|     Blender|Home Appliance|  150|       1|                 15|      2023-08-03|\n",
            "|             6|        105|       Shoes|       Fashion|   60|       1|                 20|      2023-08-04|\n",
            "|             7|        106|Refrigerator|Home Appliance|  800|       1|                 25|      2023-08-05|\n",
            "+--------------+-----------+------------+--------------+-----+--------+-------------------+----------------+\n",
            "\n",
            "+--------------+-----------+-------+-----------+-----+--------+-------------------+----------------+\n",
            "|transaction_id|customer_id|product|   category|price|quantity|discount_percentage|transaction_date|\n",
            "+--------------+-----------+-------+-----------+-----+--------+-------------------+----------------+\n",
            "|             1|        101| Laptop|Electronics| 1000|       1|                 10|      2023-08-01|\n",
            "+--------------+-----------+-------+-----------+-----+--------+-------------------+----------------+\n",
            "\n",
            "+--------------+------------+\n",
            "|      category|avg_quantity|\n",
            "+--------------+------------+\n",
            "|       Fashion|         2.0|\n",
            "|   Electronics|        1.75|\n",
            "|Home Appliance|         1.0|\n",
            "|         Books|         4.0|\n",
            "+--------------+------------+\n",
            "\n",
            "+--------------+-----------+-------------+\n",
            "|transaction_id|customer_id|product_count|\n",
            "+--------------+-----------+-------------+\n",
            "+--------------+-----------+-------------+\n",
            "\n",
            "+--------------+-------------------+\n",
            "|transaction_id|transaction_revenue|\n",
            "+--------------+-------------------+\n",
            "|             2|             1330.0|\n",
            "|             1|              900.0|\n",
            "|             7|              600.0|\n",
            "+--------------+-------------------+\n",
            "\n",
            "+----------------+------------------+\n",
            "|transaction_date|total_transactions|\n",
            "+----------------+------------------+\n",
            "|      2023-08-01|                 2|\n",
            "|      2023-08-02|                 1|\n",
            "|      2023-08-03|                 2|\n",
            "|      2023-08-06|                 2|\n",
            "|      2023-08-04|                 1|\n",
            "|      2023-08-05|                 2|\n",
            "+----------------+------------------+\n",
            "\n",
            "+-----------+-----------+\n",
            "|customer_id|total_spent|\n",
            "+-----------+-----------+\n",
            "|        102|     1870.0|\n",
            "+-----------+-----------+\n",
            "\n",
            "+--------------+------------+\n",
            "|      category|avg_discount|\n",
            "+--------------+------------+\n",
            "|       Fashion|        10.0|\n",
            "|   Electronics|        8.75|\n",
            "|Home Appliance|        15.0|\n",
            "|         Books|         0.0|\n",
            "+--------------+------------+\n",
            "\n",
            "+--------------+-----------+------------+--------------+-----+--------+-------------------+----------------+-----------+\n",
            "|transaction_id|customer_id|     product|      category|price|quantity|discount_percentage|transaction_date|final_price|\n",
            "+--------------+-----------+------------+--------------+-----+--------+-------------------+----------------+-----------+\n",
            "|             1|        101|      Laptop|   Electronics| 1000|       1|                 10|      2023-08-01|      900.0|\n",
            "|             2|        102|  Smartphone|   Electronics|  700|       2|                  5|      2023-08-01|      665.0|\n",
            "|             3|        103|       Shirt|       Fashion|   40|       3|                  0|      2023-08-02|       40.0|\n",
            "|             4|        104|     Blender|Home Appliance|  150|       1|                 15|      2023-08-03|      127.5|\n",
            "|             5|        101|  Headphones|   Electronics|  100|       2|                 10|      2023-08-03|       90.0|\n",
            "|             6|        105|       Shoes|       Fashion|   60|       1|                 20|      2023-08-04|       48.0|\n",
            "|             7|        106|Refrigerator|Home Appliance|  800|       1|                 25|      2023-08-05|      600.0|\n",
            "|             8|        107|        Book|         Books|   20|       4|                  0|      2023-08-05|       20.0|\n",
            "|             9|        108|     Toaster|Home Appliance|   30|       1|                  5|      2023-08-06|       28.5|\n",
            "|            10|        102|      Tablet|   Electronics|  300|       2|                 10|      2023-08-06|      270.0|\n",
            "+--------------+-----------+------------+--------------+-----+--------+-------------------+----------------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Banking Transactions\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "banking_data = [\n",
        "    (1, 201, \"Deposit\", 5000, \"2023-09-01\"),\n",
        "    (2, 202, \"Withdrawal\", 2000, \"2023-09-01\"),\n",
        "    (3, 203, \"Deposit\", 3000, \"2023-09-02\"),\n",
        "    (4, 201, \"Withdrawal\", 1500, \"2023-09-02\"),\n",
        "    (5, 204, \"Deposit\", 10000, \"2023-09-03\"),\n",
        "    (6, 205, \"Withdrawal\", 500, \"2023-09-03\"),\n",
        "    (7, 202, \"Deposit\", 2500, \"2023-09-04\"),\n",
        "    (8, 206, \"Withdrawal\", 700, \"2023-09-04\"),\n",
        "    (9, 203, \"Deposit\", 4000, \"2023-09-05\"),\n",
        "    (10, 204, \"Withdrawal\", 3000, \"2023-09-05\")\n",
        "]\n",
        "banking_columns = [\"transaction_id\", \"customer_id\", \"transaction_type\", \"amount\", \"transaction_date\"]\n",
        "df = spark.createDataFrame(banking_data, banking_columns)"
      ],
      "metadata": {
        "id": "Gu1vyO0R4i-u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Calculate the Total Deposit and Withdrawal Amounts\n",
        "total_by_type = df.groupBy(\"transaction_type\").agg(sum(\"amount\").alias(\"total_amount\"))\n",
        "total_by_type.show()\n",
        "\n",
        "# 2. Filter Transactions Greater Than $3,000\n",
        "transactions_gt_3000 = df.filter(col(\"amount\") > 3000)\n",
        "transactions_gt_3000.show()\n",
        "\n",
        "# 3. Find the Largest Deposit Made\n",
        "largest_deposit_df = df.filter(col(\"transaction_type\") == \"Deposit\").orderBy(col(\"amount\").desc()).limit(1)\n",
        "largest_deposit_df.show()\n",
        "\n",
        "# 4. Calculate the Average Transaction Amount for Each Transaction Type\n",
        "avg_amount_by_type = df.groupBy(\"transaction_type\").agg(avg(\"amount\").alias(\"avg_amount\"))\n",
        "avg_amount_by_type.show()\n",
        "\n",
        "# 5. Find Customers Who Made Both Deposits and Withdrawals\n",
        "deposit_customers = df.filter(col(\"transaction_type\") == \"Deposit\").select(\"customer_id\").distinct()\n",
        "withdrawal_customers = df.filter(col(\"transaction_type\") == \"Withdrawal\").select(\"customer_id\").distinct()\n",
        "both_types_customers = deposit_customers.intersect(withdrawal_customers)\n",
        "both_types_customers.show()\n",
        "\n",
        "# 6. Calculate the Total Amount of Transactions per Day\n",
        "total_per_day = df.groupBy(\"transaction_date\").agg(sum(\"amount\").alias(\"total_amount\"))\n",
        "total_per_day.show()\n",
        "\n",
        "# 7. Find the Customer with the Highest Total Withdrawal\n",
        "total_withdrawal_by_customer = df.filter(col(\"transaction_type\") == \"Withdrawal\").groupBy(\"customer_id\").agg(sum(\"amount\").alias(\"total_withdrawn\"))\n",
        "highest_withdrawal_customer = total_withdrawal_by_customer.orderBy(col(\"total_withdrawn\").desc()).limit(1)\n",
        "highest_withdrawal_customer.show()\n",
        "\n",
        "# 8. Calculate the Number of Transactions for Each Customer\n",
        "transaction_count_per_customer = df.groupBy(\"customer_id\").agg(count(\"transaction_id\").alias(\"transaction_count\"))\n",
        "transaction_count_per_customer.show()\n",
        "\n",
        "# 9. Find All Transactions That Occurred on the Same Day as a Withdrawal Greater Than $1,000\n",
        "withdrawals_gt_1000 = df.filter((col(\"transaction_type\") == \"Withdrawal\") & (col(\"amount\") > 1000)).select(\"transaction_date\").distinct()\n",
        "transactions_same_day = df.join(withdrawals_gt_1000, on=\"transaction_date\")\n",
        "transactions_same_day.show()\n",
        "\n",
        "# 10. Create a New Column to Classify Transactions as \"High\" or \"Low\" Value\n",
        "df_with_classification = df.withColumn(\"transaction_value\",\n",
        "    when(col(\"amount\") > 5000, \"High\").otherwise(\"Low\"))\n",
        "df_with_classification.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbtZ_6Kr4sQy",
        "outputId": "e6300ea3-55b8-4655-fc11-5783ad41ae9d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+------------+\n",
            "|transaction_type|total_amount|\n",
            "+----------------+------------+\n",
            "|         Deposit|       24500|\n",
            "|      Withdrawal|        7700|\n",
            "+----------------+------------+\n",
            "\n",
            "+--------------+-----------+----------------+------+----------------+\n",
            "|transaction_id|customer_id|transaction_type|amount|transaction_date|\n",
            "+--------------+-----------+----------------+------+----------------+\n",
            "|             1|        201|         Deposit|  5000|      2023-09-01|\n",
            "|             5|        204|         Deposit| 10000|      2023-09-03|\n",
            "|             9|        203|         Deposit|  4000|      2023-09-05|\n",
            "+--------------+-----------+----------------+------+----------------+\n",
            "\n",
            "+--------------+-----------+----------------+------+----------------+\n",
            "|transaction_id|customer_id|transaction_type|amount|transaction_date|\n",
            "+--------------+-----------+----------------+------+----------------+\n",
            "|             5|        204|         Deposit| 10000|      2023-09-03|\n",
            "+--------------+-----------+----------------+------+----------------+\n",
            "\n",
            "+----------------+----------+\n",
            "|transaction_type|avg_amount|\n",
            "+----------------+----------+\n",
            "|         Deposit|    4900.0|\n",
            "|      Withdrawal|    1540.0|\n",
            "+----------------+----------+\n",
            "\n",
            "+-----------+\n",
            "|customer_id|\n",
            "+-----------+\n",
            "|        202|\n",
            "|        201|\n",
            "|        204|\n",
            "+-----------+\n",
            "\n",
            "+----------------+------------+\n",
            "|transaction_date|total_amount|\n",
            "+----------------+------------+\n",
            "|      2023-09-01|        7000|\n",
            "|      2023-09-02|        4500|\n",
            "|      2023-09-03|       10500|\n",
            "|      2023-09-05|        7000|\n",
            "|      2023-09-04|        3200|\n",
            "+----------------+------------+\n",
            "\n",
            "+-----------+---------------+\n",
            "|customer_id|total_withdrawn|\n",
            "+-----------+---------------+\n",
            "|        204|           3000|\n",
            "+-----------+---------------+\n",
            "\n",
            "+-----------+-----------------+\n",
            "|customer_id|transaction_count|\n",
            "+-----------+-----------------+\n",
            "|        202|                2|\n",
            "|        201|                2|\n",
            "|        203|                2|\n",
            "|        204|                2|\n",
            "|        205|                1|\n",
            "|        206|                1|\n",
            "+-----------+-----------------+\n",
            "\n",
            "+----------------+--------------+-----------+----------------+------+\n",
            "|transaction_date|transaction_id|customer_id|transaction_type|amount|\n",
            "+----------------+--------------+-----------+----------------+------+\n",
            "|      2023-09-01|             1|        201|         Deposit|  5000|\n",
            "|      2023-09-01|             2|        202|      Withdrawal|  2000|\n",
            "|      2023-09-02|             3|        203|         Deposit|  3000|\n",
            "|      2023-09-02|             4|        201|      Withdrawal|  1500|\n",
            "|      2023-09-05|             9|        203|         Deposit|  4000|\n",
            "|      2023-09-05|            10|        204|      Withdrawal|  3000|\n",
            "+----------------+--------------+-----------+----------------+------+\n",
            "\n",
            "+--------------+-----------+----------------+------+----------------+-----------------+\n",
            "|transaction_id|customer_id|transaction_type|amount|transaction_date|transaction_value|\n",
            "+--------------+-----------+----------------+------+----------------+-----------------+\n",
            "|             1|        201|         Deposit|  5000|      2023-09-01|              Low|\n",
            "|             2|        202|      Withdrawal|  2000|      2023-09-01|              Low|\n",
            "|             3|        203|         Deposit|  3000|      2023-09-02|              Low|\n",
            "|             4|        201|      Withdrawal|  1500|      2023-09-02|              Low|\n",
            "|             5|        204|         Deposit| 10000|      2023-09-03|             High|\n",
            "|             6|        205|      Withdrawal|   500|      2023-09-03|              Low|\n",
            "|             7|        202|         Deposit|  2500|      2023-09-04|              Low|\n",
            "|             8|        206|      Withdrawal|   700|      2023-09-04|              Low|\n",
            "|             9|        203|         Deposit|  4000|      2023-09-05|              Low|\n",
            "|            10|        204|      Withdrawal|  3000|      2023-09-05|              Low|\n",
            "+--------------+-----------+----------------+------+----------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}